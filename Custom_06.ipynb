{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import time\n",
    "import contextlib\n",
    "import io\n",
    "import re\n",
    "import string\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, TextVectorization, StringLookup\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for cleaning up the text a bit\n",
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.replace(\"Project Gutenberg\", \"\")\n",
    "    text = text.replace(\"Gutenberg\", \"\")\n",
    "\n",
    "    # Remove carriage returns\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "\n",
    "    # fix quotes\n",
    "    text = text.replace(\"“\", \"\\\"\")\n",
    "    text = text.replace(\"”\", \"\\\"\")\n",
    "\n",
    "    # Replace any capital letter at the start of a word with ^ followed by the lowercase letter\n",
    "    text = re.sub(r\"(?<![a-zA-Z])([A-Z])\", lambda match: f\"^{match.group(0).lower()}\", text)\n",
    "\n",
    "    # Replace all other capital letters with lowercase\n",
    "    text = re.sub(r\"([A-Z])\", lambda match: f\"{match.group(0).lower()}\", text)\n",
    "\n",
    "    # Remove duplicate whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\n+\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\t+\", \"\\t\", text)\n",
    "\n",
    "    # Replace whitespace characters with special words\n",
    "    # text = re.sub(r\"(\\t)\", r\" zztabzz \", text)\n",
    "    # text = re.sub(r\"(\\n)\", r\" zznewlinezz \", text)\n",
    "    # text = re.sub(r\"(\\s)\", r\" zzspacezz \", text)\n",
    "\n",
    "    # possibly replace all new lines with a space then deal with duplicate whitespaces\n",
    "    # then find end of sentences via [., ?, !] and add return lines after those\n",
    "\n",
    "    # Split before and after punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, f\" {punctuation} \")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(text):\n",
    "\n",
    "    # Replace special words with whitespace characters\n",
    "    text = text.replace(\"zztabzz\", \"\\t\")\n",
    "    text = text.replace(\"zznewlinezz\", \"\\n\")\n",
    "    text = text.replace(\"zzspacezz\", \" \")\n",
    "\n",
    "    # Remake capital letters at beginning of words\n",
    "    text = re.sub(r\"\\^([a-z])\", lambda match: f\"{match.group(1).upper()}\", text)\n",
    "    text = text.replace(\"^\", \"\")\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMyText():\n",
    "    file_name = 'austen.txt'\n",
    "    local_dir = 'Module 6'  # Directory of the file\n",
    "    local_path = os.path.join(local_dir, file_name)\n",
    "\n",
    "    try:\n",
    "        # Ensure the directory exists\n",
    "        if not os.path.exists(local_dir):\n",
    "            os.makedirs(local_dir)\n",
    "\n",
    "        # Check if the file exists locally\n",
    "        if os.path.exists(local_path):\n",
    "            print(f\"File '{file_name}' found locally. Using it.\")\n",
    "        else:\n",
    "            print(f\"File '{file_name}' not found locally. Need to build it.\")\\\n",
    "\n",
    "        # Read the file's contents\n",
    "        with open(local_path, 'rb') as file:\n",
    "            text = file.read().decode(encoding='utf-8')\n",
    "\n",
    "        return preprocess_text(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Text and Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'austen.txt' found locally. Using it.\n"
     ]
    }
   ],
   "source": [
    "text = getMyText()\n",
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "# use the get_vocabulary() method from StringLookup so that the [UNK] tokens are set the same way ie...\n",
    "# This returns a tf.RaggedTensor of characters\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_it = False\n",
    "\n",
    "# Joining the chars back into strings use tf.strings.reduce_join ie...\n",
    "if vis_it:\n",
    "    example_texts = ['abcdefg', 'xyz']\n",
    "    chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "    ids = ids_from_chars(chars)\n",
    "    chars_back = chars_from_ids(ids)\n",
    "    tf.strings.reduce_join(chars_back, axis=-1).numpy()\n",
    "    print(f\"Chars split: {chars}\")\n",
    "    print(f\"\\nIds from chars: {ids}\")\n",
    "    print(f\"\\nChars from ids: {chars_back}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Training Examples and Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 128\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "def print_divider():\n",
    "    print(\"\\n=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_it = False\n",
    "\n",
    "if vis_it:\n",
    "    print(f\"All ids: {all_ids}\")\n",
    "    print_divider()\n",
    "    print(\"Stream of character indices:\")\n",
    "    for ids in ids_dataset.take(10):\n",
    "        print(chars_from_ids(ids).numpy().decode('utf-8'))\n",
    "    print_divider()\n",
    "    print(\"Sequence:\")\n",
    "    for seq in sequences.take(1):\n",
    "        print(chars_from_ids(seq))\n",
    "    print_divider()\n",
    "    print(\"Joint tokens as a string:\")\n",
    "    for seq in sequences.take(5):\n",
    "        print(text_from_ids(seq).numpy())\n",
    "    print_divider()\n",
    "    print(f\"Splitup 'Tensorflow': {split_input_target(list(\"Tensorflow\"))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_it = False\n",
    "\n",
    "if vis_it:\n",
    "    for input_example, target_example in dataset.take(1):\n",
    "        print(\"Input: \", text_from_ids(input_example).numpy())\n",
    "        print(\"Target: \", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: <_PrefetchDataset element_spec=(TensorSpec(shape=(64, 128), dtype=tf.int64, name=None), TensorSpec(shape=(64, 128), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "vis_it = True\n",
    "\n",
    "if vis_it:\n",
    "    print(f\"Dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        print(f\"Inputs: {inputs}\")\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        print(f\"Inputs embedded: {x}\")\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        \n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[ 1  1  3 ... 43 49 42]\n",
      " [29 42 32 ... 40 53  1]\n",
      " [42  1  9 ...  1 47 36]\n",
      " ...\n",
      " [32  1 42 ...  1 27  1]\n",
      " [29 49 42 ... 32  1 29]\n",
      " [ 1 43 34 ... 49 46 33]]\n",
      "Inputs embedded: Tensor(\"embedding_1_1/GatherV2:0\", shape=(64, 128, 256), dtype=float32)\n",
      "Inputs: [[ 1  1  3 ... 43 49 42]\n",
      " [29 42 32 ... 40 53  1]\n",
      " [42  1  9 ...  1 47 36]\n",
      " ...\n",
      " [32  1 42 ...  1 27  1]\n",
      " [29 49 42 ... 32  1 29]\n",
      " [ 1 43 34 ... 49 46 33]]\n",
      "Inputs embedded: [[[ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 8.3964095e-03  2.9478099e-02 -4.1531194e-02 ... -2.9927183e-02\n",
      "    4.4999074e-02  9.7370148e-03]\n",
      "  ...\n",
      "  [ 1.2128472e-02 -1.9998372e-02  1.5060712e-02 ...  3.9490089e-03\n",
      "    1.6640872e-05 -3.8105916e-02]\n",
      "  [ 1.6777005e-02 -1.3211727e-02 -2.5632013e-02 ... -2.4492312e-02\n",
      "   -4.7994804e-02  1.0712635e-02]\n",
      "  [ 3.2603826e-02  1.8757094e-02 -2.0467043e-03 ... -8.3068386e-03\n",
      "   -9.7133145e-03 -6.1062090e-03]]\n",
      "\n",
      " [[ 1.4371347e-02  1.5433382e-02  3.9800052e-02 ...  2.8972927e-02\n",
      "   -2.3231721e-02  3.5721064e-03]\n",
      "  [ 3.2603826e-02  1.8757094e-02 -2.0467043e-03 ... -8.3068386e-03\n",
      "   -9.7133145e-03 -6.1062090e-03]\n",
      "  [-2.3250997e-02  2.9185299e-02  6.6750124e-04 ... -4.8721053e-02\n",
      "   -4.9867798e-02  1.8356111e-02]\n",
      "  ...\n",
      "  [ 1.0105930e-02 -3.3033095e-02  4.3896113e-02 ... -4.8092294e-02\n",
      "   -2.0769954e-02 -2.2400737e-02]\n",
      "  [ 1.8754032e-02 -2.8065920e-02 -6.4369291e-04 ...  1.4501121e-02\n",
      "    2.9548313e-02 -2.2319078e-02]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]]\n",
      "\n",
      " [[ 3.2603826e-02  1.8757094e-02 -2.0467043e-03 ... -8.3068386e-03\n",
      "   -9.7133145e-03 -6.1062090e-03]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [-4.7489978e-02  3.6672503e-04  2.6671495e-02 ... -2.3925722e-02\n",
      "    2.3215655e-02  4.0688250e-02]\n",
      "  ...\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 3.9315652e-02  6.0282350e-03 -3.0571485e-02 ... -2.3772646e-02\n",
      "   -7.6148026e-03 -2.4657095e-02]\n",
      "  [-3.6660481e-02 -4.6671618e-02  2.0577919e-02 ... -3.4621678e-02\n",
      "   -1.7469011e-02 -4.2526796e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.3250997e-02  2.9185299e-02  6.6750124e-04 ... -4.8721053e-02\n",
      "   -4.9867798e-02  1.8356111e-02]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 3.2603826e-02  1.8757094e-02 -2.0467043e-03 ... -8.3068386e-03\n",
      "   -9.7133145e-03 -6.1062090e-03]\n",
      "  ...\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 3.7248719e-02  1.0084964e-02 -2.1941518e-02 ... -7.1550831e-03\n",
      "   -1.6155969e-02 -1.7965101e-02]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]]\n",
      "\n",
      " [[ 1.4371347e-02  1.5433382e-02  3.9800052e-02 ...  2.8972927e-02\n",
      "   -2.3231721e-02  3.5721064e-03]\n",
      "  [ 1.6777005e-02 -1.3211727e-02 -2.5632013e-02 ... -2.4492312e-02\n",
      "   -4.7994804e-02  1.0712635e-02]\n",
      "  [ 3.2603826e-02  1.8757094e-02 -2.0467043e-03 ... -8.3068386e-03\n",
      "   -9.7133145e-03 -6.1062090e-03]\n",
      "  ...\n",
      "  [-2.3250997e-02  2.9185299e-02  6.6750124e-04 ... -4.8721053e-02\n",
      "   -4.9867798e-02  1.8356111e-02]\n",
      "  [ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 1.4371347e-02  1.5433382e-02  3.9800052e-02 ...  2.8972927e-02\n",
      "   -2.3231721e-02  3.5721064e-03]]\n",
      "\n",
      " [[ 3.4523021e-02  3.3066604e-02  4.9687374e-02 ... -1.7727185e-02\n",
      "   -1.6640473e-02  1.0234334e-02]\n",
      "  [ 1.2128472e-02 -1.9998372e-02  1.5060712e-02 ...  3.9490089e-03\n",
      "    1.6640872e-05 -3.8105916e-02]\n",
      "  [ 8.4451064e-03 -4.1583575e-02 -2.2693885e-02 ... -1.8623054e-02\n",
      "    2.9056072e-03 -4.3678522e-02]\n",
      "  ...\n",
      "  [ 1.6777005e-02 -1.3211727e-02 -2.5632013e-02 ... -2.4492312e-02\n",
      "   -4.7994804e-02  1.0712635e-02]\n",
      "  [-1.1278488e-02 -2.1404957e-02  2.6748404e-03 ...  2.3130540e-02\n",
      "    4.0005397e-02 -2.1586705e-02]\n",
      "  [ 3.2475557e-02 -2.5453223e-02 -2.0359898e-02 ... -4.0753521e-02\n",
      "   -3.6369719e-02  4.7717165e-02]]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling MyModel.call().\n\n\u001b[1m{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [64,128,256] != values[1].shape = [] [Op:Pack] name: \u001b[0m\n\nArguments received by MyModel.call():\n  • inputs=tf.Tensor(shape=(64, 128), dtype=int64)\n  • states=None\n  • return_state=False\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m input_example_batch, target_example_batch \u001b[38;5;129;01min\u001b[39;00m dataset.take(\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     example_batch_predictions = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_example_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(example_batch_predictions.shape, \u001b[33m\"\u001b[39m\u001b[33m# (batch_size, sequence_length, vocab_size)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Zhenterigone\\Documents\\School\\Machine-Learning\\.venv_tf_old\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mMyModel.call\u001b[39m\u001b[34m(self, inputs, states, return_state, training)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInputs embedded: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgru\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_initial_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m x, states = \u001b[38;5;28mself\u001b[39m.gru(x, initial_state=states, training=training)\n\u001b[32m     17\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dense(x, training=training)\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Exception encountered when calling MyModel.call().\n\n\u001b[1m{{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Shapes of all inputs must match: values[0].shape = [64,128,256] != values[1].shape = [] [Op:Pack] name: \u001b[0m\n\nArguments received by MyModel.call():\n  • inputs=tf.Tensor(shape=(64, 128), dtype=int64)\n  • states=None\n  • return_state=False\n  • training=False"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
